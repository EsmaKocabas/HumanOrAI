# KatkÄ±da Bulunma Rehberi

# HumanOrAI 

### 1. Gereksinimler

- Python 3.7 veya Ã¼zeri
- pip (Python paket yÃ¶neticisi)

### 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme

Proje dizininde terminal/komut satÄ±rÄ±nÄ± aÃ§Ä±n ve ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
pip install -r requirements.txt
```

## ğŸ“¥ ArXiv Scraper KullanÄ±mÄ±

### Standart veri Ã§ekim akÄ±ÅŸÄ± (herkes iÃ§in aynÄ±)

1. Tek terminal aÃ§ ve aÅŸaÄŸÄ±daki ortam deÄŸiÅŸkenlerini yalnÄ±zca o oturum iÃ§in ayarla:
   ```powershell
   $env:HUMANORAI_ALLOW_SCRAPE = "1"
   $env:PYTHONIOENCODING = "utf-8"
   ```
2. Scraperâ€™Ä± Ã§alÄ±ÅŸtÄ±r:
   ```powershell
   python scraping_scripts\arxiv_scraper.py --target 3000
   ```
3. Terminalde `ğŸ’¾ .../3000` loglarÄ±nÄ± ve sonunda `âœ… Ä°ÅŸlem tamamlandÄ±. Toplam 3000 Ã¶zet hazÄ±r.` mesajÄ±nÄ± gÃ¶rmeden pencereyi kapatma.

> Script, reCAPTCHA yÃ¼zÃ¼nden 3000â€™e ulaÅŸamazsa hata fÄ±rlatÄ±r. Bu durumda birkaÃ§ dakika bekleyip adÄ±m 2â€™den itibaren tekrarlayÄ±n (dosyayÄ± silmeyi unutmayÄ±n).

## 1ï¸âƒ£ API Key Alma

1. **Google AI Studio**'ya gidin: https://aistudio.google.com/apikey
2. **"Create API Key"** butonuna tÄ±klayÄ±n
3. Google hesabÄ±nÄ±zla giriÅŸ yapÄ±n
4. API key'inizi kopyalayÄ±n

## 2ï¸âƒ£ .env DosyasÄ± OluÅŸturma

Proje klasÃ¶rÃ¼nÃ¼zde `.env` dosyasÄ± oluÅŸturun:

```powershell
# Windows PowerShell
cd C:\Users\Esma\Desktop\HumanOrAI
```

`.env` dosyasÄ±nÄ± oluÅŸturun ve iÃ§ine ÅŸunu yazÄ±n:

```
GEMINI_API_KEY=your-api-key-here
```

**Ã–rnek:**
```
GEMINI_API_KEY=AIzaSyDxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

> âš ï¸ **Ã–nemli:** `.env` dosyasÄ± `.gitignore`'a eklenmiÅŸtir, API key'iniz GitHub'a yÃ¼klenmeyecektir.

## 3ï¸âƒ£ BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme

```powershell
pip install -r requirements.txt
```

## 4ï¸âƒ£ AI Abstract'larÄ± Ãœretme

### Temel KullanÄ±m (3000 kayÄ±t):

```powershell
python scraping_scripts\gemini_scraper.py --target 3000
```

## 5ï¸âƒ£ Verileri BirleÅŸtirme

Human ve AI verilerini birleÅŸtirmek iÃ§in:

```powershell
python scraping_scripts\combine_datasets.py
```

### Ã–zelleÅŸtirilmiÅŸ birleÅŸtirme:

```powershell
python scraping_scripts\combine_datasets.py --human data\raw\human_abstracts.csv --ai data\raw\ai_abstracts.csv --output data\raw\combined_dataset.csv
```

### Shuffle (karÄ±ÅŸtÄ±rma) olmadan:

```powershell
python scraping_scripts\combine_datasets.py --no-shuffle
```



### Ekip Ã‡alÄ±ÅŸmasÄ±

**Ã–nemli:** CSV dosyalarÄ± GitHub'a atÄ±lmaz (`.gitignore` ile engellendi). Her ekip Ã¼yesi kendi bilgisayarÄ±nda sÄ±fÄ±rdan veri Ã§eker.

**Ã‡alÄ±ÅŸma Åekli:**
1. Herkes projeyi klonlar ve `pip install -r requirements.txt` Ã§alÄ±ÅŸtÄ±rÄ±r
2. Herkes yukarÄ±daki standart akÄ±ÅŸÄ± uygular (aynen aynÄ± adÄ±mlar)
3. Herkesin `data/raw/human_abstracts.csv` dosyasÄ±nda **3000 satÄ±r** olana kadar sÃ¼reci tekrarlar

**Not:** CSV dosyasÄ± var ise script kaldÄ±ÄŸÄ± yerden devam eder. Standart akÄ±ÅŸ gereÄŸi sÄ±fÄ±rdan baÅŸlamak iÃ§in Ã¶nce dosyayÄ± silin veya yedekleyin.

**FarklÄ± dosya adÄ± kullanmak iÃ§in:**
```bash
python scraping_scripts/arxiv_scraper.py --output data/raw/human_abstracts_2.csv
```

### Ã‡Ä±ktÄ± FormatÄ±

CSV dosyasÄ± ÅŸu sÃ¼tunlarÄ± iÃ§erir:
- `abstract_text`: Makale Ã¶zeti (dÃ¼z metin)
- `source_url`: ArXiv.org'daki makale URL'si
- `license_info`: Lisans bilgisi
- `label`: "Human" veya "AI" etiketi


## GeliÅŸtirme Ä°ÅŸ AkÄ±ÅŸÄ±

1. **Yeni branch oluÅŸtur**:
   ```bash
   git checkout -b feature/yeni-ozellik
   ```

2. **DeÄŸiÅŸiklikleri yap ve commit et**:
   ```bash
   git add .
   git commit -m "AÃ§Ä±klayÄ±cÄ± commit mesajÄ±"
   ```

3. **Push yap**:
   ```bash
   git push origin feature/yeni-ozellik
   ```

4. **Pull Request oluÅŸtur** (GitHub'da)
