# HumanOrAI

YazÄ±lan metnin AI tarafÄ±ndan mÄ± insan tarafÄ±ndan mÄ± yazÄ±ldÄ±ÄŸÄ±nÄ± tespit eden bir makine Ã¶ÄŸrenmesi projesi ve web uygulamasÄ±.

## ğŸ“‹ Proje HakkÄ±nda

Bu proje, akademik makale Ã¶zetlerini (abstracts) analiz ederek bunlarÄ±n insan tarafÄ±ndan mÄ± yoksa AI (yapay zeka) tarafÄ±ndan mÄ± yazÄ±ldÄ±ÄŸÄ±nÄ± tespit etmek iÃ§in geliÅŸtirilmiÅŸtir.

## ğŸ¯ Ã–zellikler

- **Veri Toplama**: ArXiv'den 3000 human abstract Ã§ekme
- **AI Veri Ãœretimi**: Gemini API ile human abstract'larÄ±nÄ± AI tarzÄ±nda yeniden yazma
- **Veri BirleÅŸtirme**: Human ve AI verilerini birleÅŸtirme ve karÄ±ÅŸtÄ±rma
- **Model EÄŸitimi**: Ä°nsan vs AI metin sÄ±nÄ±flandÄ±rma modeli eÄŸitimi (yakÄ±nda)

## ğŸ“ Proje YapÄ±sÄ±

```
HumanOrAI/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/              # CSV veri dosyalarÄ± (git'te yok)
â”‚       â”œâ”€â”€ human_abstracts.csv
â”‚       â”œâ”€â”€ ai_abstracts.csv
â”‚       â””â”€â”€ combined_dataset.csv
â”œâ”€â”€ scraping_scripts/
â”‚   â”œâ”€â”€ arxiv_scraper.py      # ArXiv'den human veri Ã§ekme
â”‚   â”œâ”€â”€ gemini_scraper.py     # Gemini API ile AI veri Ã¼retme
â”‚   â””â”€â”€ combine_datasets.py   # Verileri birleÅŸtirme
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ README.md
```

## ğŸš€ Kurulum

### 1. Projeyi KlonlayÄ±n

```bash
git clone https://github.com/EsmaKocabas/HumanOrAI.git
cd HumanOrAI
```

### 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
pip install -r requirements.txt
```

### 3. Environment Variables

`.env` dosyasÄ± oluÅŸturun:

```env
GEMINI_API_KEY=your-api-key-here
```

> **Not**: API key almak iÃ§in: https://aistudio.google.com/apikey

## ğŸ“– KullanÄ±m

### Human Verileri Ã‡ekme

```bash
# PowerShell'de ortam deÄŸiÅŸkenini ayarlayÄ±n
$env:HUMANORAI_ALLOW_SCRAPE = "1"

# Scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n
python scraping_scripts/arxiv_scraper.py --target 3000
```

### AI Verileri Ãœretme

```bash
python scraping_scripts/gemini_scraper.py --target 3000
```

### Verileri BirleÅŸtirme

```bash
python scraping_scripts/combine_datasets.py
```

Ã‡Ä±ktÄ±: `data/raw/combined_dataset.csv` (6000 kayÄ±t: 3000 Human + 3000 AI)

## ğŸ‘¥ Ekip Ã‡alÄ±ÅŸmasÄ±

Her ekip Ã¼yesi:
1. Projeyi klonlar
2. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kler
3. Kendi API key'ini `.env` dosyasÄ±na ekler
4. AynÄ± komutlarÄ± Ã§alÄ±ÅŸtÄ±rarak verileri Ã§eker

> **Ã–nemli**: CSV dosyalarÄ± git'te yok (`.gitignore` ile engellendi). Herkes kendi verilerini Ã§ekmelidir.

## ğŸ“ DetaylÄ± DokÃ¼mantasyon

Daha fazla bilgi iÃ§in [CONTRIBUTING.md](CONTRIBUTING.md) dosyasÄ±na bakÄ±n.

## ğŸ”§ GeliÅŸtirme

1. Yeni branch oluÅŸtur: `git checkout -b feature/yeni-ozellik`
2. DeÄŸiÅŸiklikleri yap ve commit et
3. Push yap: `git push origin feature/yeni-ozellik`
4. Pull Request oluÅŸtur

## ğŸ“Š Veri Ä°statistikleri

- **Human Abstracts**: 3000
- **AI Abstracts**: 3000
- **Toplam**: 6000

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir.

## ğŸ‘¨â€ğŸ’» Yazar

- **Esma KoÃ§abaÅŸ** - [@EsmaKocabas](https://github.com/EsmaKocabas)

## ğŸ™ KatkÄ±da Bulunanlar

Projeye katkÄ±da bulunan herkese teÅŸekkÃ¼rler!

---

**Not**: Veri dosyalarÄ± GitHub'a yÃ¼klenmez (Ã§ok bÃ¼yÃ¼k olduÄŸu iÃ§in). Her ekip Ã¼yesi kendi verilerini Ã§ekmelidir.
